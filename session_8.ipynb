{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding\n",
    "\n",
    "Teknik representasi kata-kata dalam bentuk vector dengan dimensi vector yang rendah.\n",
    "\n",
    "Kata-kata dengan makna yang mirip akan memiliki representasi vector yang mendekati satu sama lain dalam ruang tersebut.\n",
    "\n",
    "Nah, disini ada beberapa jenis algoritma Word Embedding yaitu:\n",
    "\n",
    "- TF-IDF (Term Frequency Inverse Document Frequency)\n",
    "- BoW (Bag of Words)\n",
    "\n",
    "Nah, disini yang bakal kita pelajari tuh cuman TF-IDF aja.\n",
    "Nah ini tuh apa sih? Ini tuh technically adalah suatu metode statistic untuk menilai **pentingnya suatu kata dalam sebuah dokumen dalam kumpulan dokumen**\n",
    "Cara tau pentingnya gimana? Disini ada istilah TF dan IDF.\n",
    "* TF -> Term-Frequency akan kita gunakan untuk mengukur banyaknya suatu kata muncul dalam suatu document.\n",
    "* IDF -> Inverse-Document-Frequency yang artinya kita akan memberi bobot tambahan pada kata-kata yang jarang muncul pada document tersebut dan memberi nilai tambahan bagi kata-kata yang dianggap lebih informative.\n",
    "\n",
    "Rumusnya:\n",
    "```bash\n",
    "TF(t,d) * IDF(t)\n",
    "\n",
    "t = term frequency (number of times term 't' appears in doc 'd')\n",
    "\n",
    "rumus IDF:\n",
    "```\n",
    "liat sendiri di discord @admantix :v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library yang kita perlukan\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import math\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'another', 'is', 'a', 'This', 'sentence'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>another</th>\n",
       "      <th>is</th>\n",
       "      <th>a</th>\n",
       "      <th>This</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   another  is  a  This  sentence\n",
       "0        0   1  1     1         1\n",
       "1        1   1  0     1         1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to use TF-IDF methods\n",
    "first_sentence = \"This is a sentence\"\n",
    "second_sentence = \"This is another sentence\"\n",
    "\n",
    "# tokenisasi\n",
    "first_sentence = word_tokenize(first_sentence)\n",
    "second_sentence = word_tokenize(second_sentence)\n",
    "total = set(first_sentence).union(set(second_sentence)) # ambil yang muncul di kedua dokumen (union)\n",
    "print(total)\n",
    "\n",
    "# hitung frekuensi kemunculan kata (pake hashmap)\n",
    "wordDictA = dict.fromkeys(total, 0)\n",
    "wordDictB = dict.fromkeys(total, 0)\n",
    "for word in first_sentence:\n",
    "    wordDictA[word] += 1\n",
    "for word in second_sentence:\n",
    "    wordDictB[word] += 1\n",
    "\n",
    "pd.DataFrame([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Komputasi nilai TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   another    is     a  This  sentence\n",
      "0     0.00  0.25  0.25  0.25      0.25\n",
      "1     0.25  0.25  0.00  0.25      0.25\n"
     ]
    }
   ],
   "source": [
    "def computeTF(wordDict, doc):\n",
    "    tfDict = {}\n",
    "    corpusCount = len(doc)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(corpusCount)\n",
    "    return tfDict\n",
    "\n",
    "tfFirst = computeTF(wordDictA, first_sentence)\n",
    "tfSecond = computeTF(wordDictB, second_sentence)\n",
    "\n",
    "tf = pd.DataFrame([tfFirst, tfSecond])\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter kalimatnya (gunakan stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['another', 'This', 'sentence']\n"
     ]
    }
   ],
   "source": [
    "eng_stopwords = stopwords.words('english')\n",
    "filtered_sentence = [word for word in wordDictA if word not in eng_stopwords]\n",
    "\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hitung IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Term      IDF\n",
      "0   another  0.30103\n",
      "1        is  0.30103\n",
      "2         a  0.30103\n",
      "3      This  0.30103\n",
      "4  sentence  0.30103\n"
     ]
    }
   ],
   "source": [
    "def computeIDF(docList):\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "\n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / (float(val) + 1)) # Representasi rumus IDF ada disini semua\n",
    "    \n",
    "    idf_df = pd.DataFrame(list(idfDict.items()), columns=['Term', 'IDF'])\n",
    "    return idf_df\n",
    "\n",
    "idfs = computeIDF([wordDictA, wordDictB])\n",
    "print(idfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Komputasikan TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    another        is         a      This  sentence\n",
      "0  0.000000  0.075257  0.075257  0.075257  0.075257\n",
      "1  0.075257  0.075257  0.000000  0.075257  0.075257\n"
     ]
    }
   ],
   "source": [
    "def computeIDF(tfBoW, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBoW.items():\n",
    "        tfidf[word] = val * idfs.loc[idfs['Term'] == word, 'IDF'].iloc[0]\n",
    "    return tfidf\n",
    "\n",
    "tfidfFirst = computeIDF(tfFirst, idfs)\n",
    "tfidfSecond = computeIDF(tfSecond, idfs)\n",
    "\n",
    "tfidf = pd.DataFrame([tfidfFirst, tfidfSecond])\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF menggunakan library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a sentence', 'This is another sentence']\n",
      "['another' 'is' 'sentence' 'this']\n",
      "Document 1:  ['this', 'is', 'sentence']\n",
      "Document 2:  ['this', 'is', 'another', 'sentence']\n",
      "0.7765145304745157\n"
     ]
    }
   ],
   "source": [
    "Document1 = \"This is a sentence\"\n",
    "Document2 = \"This is another sentence\"\n",
    "\n",
    "Doc = [Document1, Document2]\n",
    "print(Doc)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "# Menghitung TF-IDF\n",
    "X = vectorizer.fit_transform(Doc)\n",
    "print(vectorizer.get_feature_names_out())   # kata yang muncul\n",
    "\n",
    "print(\"Document 1: \", analyzer(Document1))\n",
    "print(\"Document 2: \", analyzer(Document2))\n",
    "\n",
    "x1 = X.toarray()[0]\n",
    "x2 = X.toarray()[1]\n",
    "\n",
    "# Cosine Similarity\n",
    "cosine_sim = np.dot(x1, x2) / (norm(x1) * norm(x2))\n",
    "print(cosine_sim) # semakin mendekati 1 semakin mirip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
