{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-grams:\n",
    "Apa itu N-grams? N-gram adalah sequence of word yang ada di dalam kalimat. Sebelumnya kita sudah mengenal yang namanya Word Tokenize dimana dia bakal mecah-mecah setiap kata yang terkandung di dalam sebuah kalimat. Bedanya dengan N-grams, N-grams akan memecah-mecah kata dalam kalimat menjadi beberapa kata dengan kasta tertentu.\n",
    "\n",
    "Contohnya:\n",
    "* Unigram -> memecah setiap kata menjadi satu per satu.\n",
    "\"This is a sentence\" -> [\"This\", \"is\", \"a\", \"sentence\"]\n",
    "nah kalau inikan persis kayak word_tokenize(). Nah, bedanya di N-gram ini, kita bakal mecah ga cuman satu per satu tapi bisa 2 kata atau 3 kata. Contoh lainnya:\n",
    "\n",
    "* Bigram -> memecah setiap kata menjadi dua kata-dua kata.\n",
    "\"This is a sentence\" -> [\"This is\", \"is a\", \"a sentence\"]\n",
    "\n",
    "* Trigram -> memecah setiap kata menjadi tiga kata-tiga kata.\n",
    "\"This is a sentence\" -> [\"This is a\", \"is a sentence\"]\n",
    "\n",
    "Semakin tinggi kasta suatu N-grams, semakin akurat model AI yang kita hasilkan. Tapi sebaliknya, semakin kecil kasta N-grams, semakin tidak akurat pula model AI yang kita hasilkan.\n",
    "\n",
    "Take notes bahwa pada kenyataannya, N-grams sendiri biasanya digunakan tidak lebih dari **Trigram**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cara menerapkan N-grams model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import library yang diperlukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer sendiri digunakan untuk mengubah data **text** menjadi representasi BackOfWords atau disingkat BOW. Singkatnya ini teh Vector\n",
    "\n",
    "Sementara cosine_similarity digunakan untuk menghitung kemiripan cosinus antara vector-vector yang kita punya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModel:\n",
    "    def __init__(self, n):\n",
    "        self.n = n # represents the n in n-gram\n",
    "        self.vectorizer = CountVectorizer(analyzer=\"word\", ngram_range=(n, n)) # membuat object CountVectorizer \n",
    "\n",
    "    def fit_transform(self, corpus):\n",
    "        return self.vectorizer.fit_transform(corpus) # menghitung frekuensi kemunculan kata dan mengubahnya menjadi vector yang dapat diolah oleh model\n",
    "    \n",
    "    def transform(self, corpus):\n",
    "        return self.vectorizer.transform(corpus) \n",
    "    \n",
    "def calculate_cosine_similarity(matrix, query_vector):\n",
    "    similarities = cosine_similarity(query_vector, matrix) # menghitung cosine similarity antara matrix dan vector query.\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contoh pemakaian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram Model: \n",
      "   chess  football  game  good  is  it  like  over  play  prefer  rugby  to\n",
      "0      0         1     0     0   0   0     1     0     1       0      0   1\n",
      "1      0         0     1     1   1   1     0     0     0       0      0   0\n",
      "2      0         1     0     0   0   0     0     1     0       1      1   0\n",
      "3      1         0     0     0   0   0     1     0     1       0      0   1\n"
     ]
    }
   ],
   "source": [
    "# Ini corpus kita yang mau dijalankan dengan N-gram language model kita\n",
    "# Ini ibaratnya dataset kita buat nge-train model N-gram language kita.\n",
    "corpus = [\n",
    "    \"I like to play football\",\n",
    "    \"It is a good game\",\n",
    "    \"I prefer football over rugby\",\n",
    "    \"I like to play chess\"\n",
    "]\n",
    "\n",
    "# query yang akan dicari cosine similarity nya\n",
    "query = \"This is the query text\"\n",
    "\n",
    "# contoh membuat unigram:\n",
    "n = 1\n",
    "\n",
    "# buat object dari class NGramLanguageModel\n",
    "ngram_language_model = NGramLanguageModel(n)\n",
    "\n",
    "# ubah file corpus kita ke bentuk matrix\n",
    "matrix = ngram_language_model.fit_transform(corpus)\n",
    "# ubah file query kita ke bentuk vector\n",
    "query_vector = ngram_language_model.transform([query])\n",
    "\n",
    "print(f\"{n}-gram Model: \")\n",
    "data = matrix.A\n",
    "\n",
    "# print data corpus kita dalam bentuk dataframe\n",
    "print(pd.DataFrame(data, columns=ngram_language_model.vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil yang ada diatas adalah bentuk mappingan dimana pada corpus index ke-0 terdapat chess sebanyak 0 kata, football sebanyak 1 kata, dan seterusnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 1 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(query_vector.A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nah, kalau yang ini tuh query text kita, dibandingin sama N-gram model kita dengan format kolom mappingan yang sama. Nah query text ini tuh lebih ke arah text-inputnya kita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the query text\n",
      "                       Document  Similarity\n",
      "0       I like to play football         0.0\n",
      "1             It is a good game         0.5\n",
      "2  I prefer football over rugby         0.0\n",
      "3          I like to play chess         0.0\n"
     ]
    }
   ],
   "source": [
    "# Kalkulasi cosine similarity corpus yang kita punya\n",
    "similarities = calculate_cosine_similarity(matrix, query_vector)\n",
    "\n",
    "# print cosine similarity\n",
    "data = {'Document': corpus, 'Similarity': similarities[0]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(f\"{query}\")\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
